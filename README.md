# pyflame

### 背景说明

```textmate
当我们处理数据规模较小时，是本地快捷开发依然是高效的解法之一，但应对大数据量时我们就必须借助于分布式计算框架。
以Spark为代表的分布式计算框架可以为我们提供了更强大的计算服务能力，但同时会存在两类问题：
1.如saL化的一类用法对于常规数据分析友好，但对于大规模型的、密集型的计算处理任务适应性也有局限性。
••此时如果继续使用sQL脚本化开发，削足适履的sQL代码就是一组繁复的套娃结构，很难进行持续维护和二次复用式升级.
•基于SQL代码实现的复杂计算流程，往往也存在着非常大的性能优化空间，如果您正在处理一个需要保证一定计算时效的大规模计 算任务，就应该果断采取第二技术路线。

2） 使用Spark一类的代码级的开发流程，可以赋子我们以更大的自由度去实现复杂的计算逻辑，但往往也会产生千人千面，高度耩合业务＋高度个性化的代码。
•使用Spark开 发需要讲究最佳安现，一些不良的代码构建方式实现的代码效能可能会比纯辉的sq/脚本实现还要低效。
•Spark算实现的代码在分布式运行条件下远不如单线程的代码好调试，在线调试又过度依赖于打印日志的方式，这种方式会随数据规模增大调试效能持续下降，
•为此，实现本地和线上兼容式的spark代码开发工具包，构建Flame框架也是致力于减少这种低质的生产效能问题。
```

### 代码构建说明

当前Pyflame原型实现实现以pyspark 3.x 为基础，核心代码仅包括四个python script.
- [1] spark_env/spark_nelper.py
  用于创建spark实例和运行时信息配置支持。
- [2] spark_env/spark_local_support.y
  用于本地spark环境和hive_table映射对齐的特性实现。
- [3] spark_env/general_aspect.py
  用于自定义函数算子
- [4] spark_env/dev_support/udtf_tester-py
  在MapPartitionUDTF定义基础上，为本地化开发调试executor执行过程提供便利性支持


-----------

> 如果您还想要更高级的功能特性支特，欢迎发起讨论。探讨更多可能.
